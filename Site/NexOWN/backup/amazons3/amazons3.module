<?php

use Aws\Common\Credentials\Credentials;
use Drupal\amazons3\Exception\S3ConnectValidationException;
use Drupal\amazons3\S3Client;
use Drupal\amazons3\S3Url;

/**
 * @file
 * Hook implementations for the AmazonS3 module.
 */

/**
 * Implements hook_stream_wrappers().
 *
 * Create a stream wrapper for S3.
 */
function amazons3_stream_wrappers() {
  // This hook is called before hook_init(), so we have to manually register
  // the autoloader. We also need to handle module upgrades where
  // composer_manager might not be enabled yet.
  if (!module_exists('composer_manager')) {
    return array();
  }

  // If the module has been enabled, but the user didn't update composer
  // libraries, prevent failing entirely.
  try {
    composer_manager_register_autoloader();
  }
  catch (\RuntimeException $e) {
    watchdog('amazons3', 'The Composer autoloader could not be registered. Run drush composer-rebuild and drush composer-manager update to update your vendor directory.');
    watchdog_exception('amazons3', $e);
    return array();
  }

  if (!class_exists('Drupal\amazons3\StreamWrapper')) {
    watchdog('amazons3', 'The AmazonS3 StreamWrapper class is missing. Make sure all module updates have run. Otherwise, run drush composer-rebuild and drush composer-manager update to update your vendor directory.');
    return array();
  }

  return array(
    's3' => array(
      'name' => 'Amazon S3',
      'class' => 'Drupal\amazons3\StreamWrapper',
      'description' => t('Amazon Simple Storage Service'),
    ),
  	's3private' => array(
  		'name' => 'Amazon S3 Private',
  		'class' => 'Drupal\amazons3\StreamWrapper',
  		'description' => t('Amazon Simple Storage Service Private'),
  	),
  );
}

/**
 * Implements hook_menu().
 */
function amazons3_menu() {
  $items = array();

  $items['admin/config/media/amazons3'] = array(
    'title' => 'Amazon S3',
    'description' => 'Configure S3 credentials and settings',
    'page callback' => 'drupal_get_form',
    'page arguments' => array('amazons3_admin'),
    'access arguments' => array('administer amazons3'),
    'file' => 'amazons3.admin.inc',
  );

  // hook_menu is called after this module is enabled, but before Composer
  // dependencies are enabled. This menu callback string should always match
  // \Drupal\amazons3\StreamWrapper::stylesCallback.
  $items['amazons3/image-derivative'] = array(
    'title' => 'Image style delivery callback',
    'description' => 'Callback to generate an image derivative, upload it to S3, and redirect to the S3 URL',
    'page callback' => 'amazons3_image_deliver',
    'access arguments' => array('access content'),
    'type' => MENU_CALLBACK,
  );

  return $items;
}

/**
 * Image delivery callback that uploads a derivative to S3.
 *
 * @param ...
 *   The path components of the source image.
 */
function amazons3_image_deliver() {

  $args = func_get_args();
  if (count($args) < 4) {
    return MENU_NOT_FOUND;
  }

  $bucket = $args[0];

  // Pop off the bucket and the 'styles' constant in the URL.
  array_shift($args);
  array_shift($args);

  $style_name = $args[0];

  // If the image style doesn't exist, we can return early.
  if (!$style = image_style_load($style_name)) {
    return MENU_NOT_FOUND;
  }

  // Pop off the style name; the rest is our key to the original image.
  array_shift($args);
  $path = $args;
  $key = implode('/', $path);

  $source = new S3Url($bucket, $key);
  $destination = $source->getImageStyleUrl($style_name);

  // Check that the image style token is valid.
  if (!variable_get('image_allow_insecure_derivatives', FALSE) || strpos($destination->getKey(), 'styles/') === 0) {
    $valid = isset($_GET[IMAGE_DERIVATIVE_TOKEN]) && $_GET[IMAGE_DERIVATIVE_TOKEN] === image_style_path_token($style['name'], (string) $source);
    if (!$valid) {
      return MENU_ACCESS_DENIED;
    }
  }

  if (!file_exists($destination)) {
    // If there is no source image we can 404 early.
    if (!file_exists($source)) {
      return MENU_NOT_FOUND;
    }

    $lock_name = 'amazons3_image_style_deliver:' . drupal_hash_base64($destination->getKey());
    $destination_temp = 'temporary://amazons3/' . $destination->getKey();

    // Prevent cache stampedes.
    if (!lock_acquire($lock_name)) {
      _amazons3_image_wait_transfer($destination_temp);
    }

    // Generate the derivative.
    if (!image_style_create_derivative($style, $source, $destination_temp)) {
      // Something went horribly wrong, but all we have is a FALSE return. Throw
      // an exception with something useful.
      throw new \Exception('Amazon S3 was unable to create an image style derivative. Check the temporary directory configuration and permissions.');
    }
    lock_release($lock_name);

    // Register a shutdown function to upload the image to S3.
    $image = amazons3_image_load($destination_temp);
    register_shutdown_function(function() use ($image, $destination) {
      // We have to call both of these to actually flush the image.
      ob_end_flush();
      flush();

      // file_unmanaged_copy() will not create any nested directories if needed.
      $directory = drupal_dirname($destination);
      if (!file_prepare_directory($directory, FILE_CREATE_DIRECTORY | FILE_MODIFY_PERMISSIONS)) {
        watchdog('amazons3', 'Failed to create style directory: %directory', array('%directory' => $directory), WATCHDOG_ERROR);
      }

      file_unmanaged_copy($image->source, $destination);
    });

    // Transfer the image to the client from our temporary directory.
    file_transfer($image->source, array('Content-Type' => $image->info['mime_type'], 'Content-Length' => $image->info['file_size']));
  }

  // If the file exists on S3, send a permanent redirect.
  /** @var \Drupal\amazons3\StreamWrapper $wrapper */
  $wrapper = file_stream_wrapper_get_instance_by_uri($destination);
  drupal_goto($wrapper->getExternalUrl(), array(), 301);
}

/**
 * Wait for an image to appear in a directory, and transfer it when it appears.
 *
 * @param string $uri
 *   The image URI to transfer.
 *
 * @return bool
 *   FALSE if the image was not transferred.
 */
function _amazons3_image_wait_transfer($uri) {
  // Another process is trying to create the file on S3. S3 uploads can
  // still be slow, so we wait for the temporary file to exist and serve
  // that.
  $tries = 0;
  while ($tries < 4 && !file_exists($uri)) {
    usleep(500000);
    $tries++;
  }

  // If the file doesn't exist, it either means we had a stale lock, or the
  // other process died and couldn't create the image style. In that case,
  // we fall through and try to create the derivative without acquiring the
  // lock.
  if (file_exists($uri)) {
    $image = amazons3_image_load($uri);
    file_transfer($uri, array('Content-Type' => $image->info['mime_type'], 'Content-Length' => $image->info['file_size']));
  }

  return FALSE;
}

/**
 * Load an image, exiting if it could not be loaded.
 *
 * @param string $uri
 *   The image URI to load.
 *
 * @return \stdClass
 *   The loaded image.
 */
function amazons3_image_load($uri) {
	
  $image = image_load($uri);
  if (!$image) {
    watchdog('amazons3', 'Unable to generate the derived image located at %path.', array('%path' => $uri));
    drupal_add_http_header('Status', '500 Internal Server Error');
    drupal_add_http_header('Content-Type', 'text/html; charset=utf-8');
    print t('Error generating image.');
    drupal_exit();
  }

  return $image;
}

/**
 * Implements hook_permission().
 */
function amazons3_permission() {
  return array(
    'administer amazons3' => array(
      'title' => t('Administer AmazonS3'),
    ),
  );
}

/**
 * Implements hook_flush_caches().
 */
function amazons3_flush_caches() {
  return array(
    'cache_amazons3_metadata',
  );
}

/**
 * Implements hook_field_info_alter().
 */
function amazons3_field_info_alter(&$info) {
  foreach (amazons3_file_like_field() as $type) {
    // Use the default bucket as specified in the module configuration.
    if (isset($info[$type])) {
      $info[$type]['settings']['amazons3_bucket'] = variable_get('amazons3_bucket', '');
    }
  }
}

/**
 * Implements hook_image_style_path_alter().
 *
 * When we are using S3, we need to rewrite image style URLs to route through
 * our own paths.
 */
function amazons3_image_style_path_alter(&$result, $style_name, $uri) {
	
  $scheme = file_uri_scheme($uri);
  if ($scheme != 's3') {
    return;
  }

  $s3url = S3Url::factory($uri);
  $result = $s3url->getImageStyleUrl($style_name);
  
}

/**
 * Return an array of field types that are like a file field.
 *
 * If a field type is calling file_* hooks to create it's field, it likely
 * belongs here.
 *
 * @return array
 *   An array of field types.
 */
function amazons3_file_like_field() {
  return array('file', 'image');
}

/**
 * Implements hook_field_widget_form_alter().
 *
 * Override file fields to use our destination function to determine the
 * upload location for a file.
 */
function amazons3_field_widget_form_alter(&$element, &$form_state, $context) {
  $field = $context['field'];
  $instance = $context['instance'];
  $delta = $context['delta'];

  if (in_array($field['type'], amazons3_file_like_field())) {
    $element[$delta]['#upload_location'] = amazons3_field_widget_uri($field, $instance);
  }
}

/**
 * Return the destination URI for a file field.
 *
 * @param array $field
 *   A field array.
 * @param array $instance
 *   A field instance array.
 * @param array $data
 *   (optional) An array of token objects to pass to token_replace().
 *
 * @see file_field_widget_uri()
 * @see token_replace()
 *
 * @return string
 *   A file directory URI with tokens replaced.
 */
function amazons3_field_widget_uri(array $field, array $instance, array $data = array()) {
  $uri_scheme = $field['settings']['uri_scheme'];
  $file_directory = isset($instance['settings']['file_directory']) ? $instance['settings']['file_directory'] : NULL;
  $bucket = isset($field['settings']['amazons3_bucket']) ? $field['settings']['amazons3_bucket'] : NULL;
  return amazons3_upload_location($uri_scheme, $bucket, $file_directory, $data);
}

/**
 * Return a URI for use in an #upload_location or similar form element.
 *
 * @param string $uri_scheme
 *   The scheme to use for the URI.
 * @param string $bucket
 *   (optional) bucket, if the URI is an s3 URI.
 * @param string $file_directory
 *   (optional) File directory for the URI.
 * @param array $data
 *   (optional) Array of data to use when replacing tokens.
 *
 * @return string
 *   A fully-qualified string URI.
 */
function amazons3_upload_location($uri_scheme, $bucket = NULL, $file_directory = NULL, array $data = array()) {

  if ($uri_scheme == 's3') {
    $destination = $bucket;

    // If no bucket is specified, but this is an S3 URI, use the default bucket.
    if (empty($destination)) {
      $config = \Drupal\amazons3\StreamWrapperConfiguration::fromDrupalVariables();
      $destination = $config->getBucket();
    }
    if (!empty($file_directory)) {
      $destination .= '/' . trim($file_directory, '/');
    }
  }
  else {
    $destination = trim($file_directory, '/');
  }

  // Replace tokens.
  $destination = token_replace($destination, $data);

  return $uri_scheme . '://' . $destination;
}

/**
 * Implements hook_form_FORM_ID_alter().
 */
function amazons3_form_field_ui_field_settings_form_alter(&$form, &$form_state, $form_id) {
  $type = $form['field']['type']['#value'];
  _amazons3_field_configuration($form, $type);
}

/**
 * Implements hook_form_FORM_ID_alter().
 *
 * Add bucket configuration to each file field form.
 */
function amazons3_form_field_ui_field_edit_form_alter(&$form, &$form_state, $form_id) {
  $type = $form['#field']['type'];
  _amazons3_field_configuration($form, $type);
}

/**
 * Implements hook_file_entity_upload_destination_uri_alter().
 */
function amazons3_file_entity_upload_destination_uri_alter(&$result, array $params = array(), array $data = array()) {
  if ($params['uri_scheme'] == 's3') {
    try {
      $url = S3Url::factory($result);
      $s3 = S3Client::factory();
      S3Client::validateBucketExists($url->getBucket(), $s3, new \Drupal\amazons3\Cache());
      $bucket = $url->getBucket();
    }
    catch (\InvalidArgumentException $e) {
      // We couldn't parse the URL, so check to see if it is bare.
      if ($result == 's3://') {
        $config = \Drupal\amazons3\StreamWrapperConfiguration::fromDrupalVariables();
        $bucket = $config->getBucket();
      }
      else {
        throw $e;
      }
    }
    catch (S3ConnectValidationException $e) {
      if (!empty($params['field']) && $field = field_info_field($params['field'])) {
        $bucket = $field['settings']['amazons3_bucket'];
      }
      else {
        $config = \Drupal\amazons3\StreamWrapperConfiguration::fromDrupalVariables();
        $bucket = $config->getBucket();
      }
    }
    $result = amazons3_upload_location('s3', $bucket, $params['file_directory'], $data);
  }
}

/**
 * Implements hook_file_stream_wrapper_uri_normalize_alter().
 */
function amazons3_file_stream_wrapper_uri_normalize_alter(&$uri, $scheme, $target) {

  if ($scheme == 's3') {
    try {
      // If this try passes, $uri is a fully-formed s3:// URI with a bucket.
      $url = S3Url::factory($uri);

      // Validate that the bucket exists. Sometimes we might be passed in URIs
      // without a bucket, like s3://image.jpg. If image.jpg is not a bucket, we
      // assume that image.jpg is supposed to be created in the default bucket.
      $s3 = S3Client::factory();
      S3Client::validateBucketExists($url->getBucket(), $s3, new \Drupal\amazons3\Cache());
    }
    catch (\InvalidArgumentException $e) {
      // Catch if S3Url::factory() can not parse $uri. That happens if we are
      // passed in a bare URI like s3://. Fall back to the default bucket.
      $uri = amazons3_uri_add_bucket($target);
    }
    catch (S3ConnectValidationException $e) {
      // Catch if a bucket does not exist or is invalid.
      $uri = amazons3_uri_add_bucket($target);
    }
  }
}

/**
 * Add the default bucket and return a string URL.
 *
 * @param string $target
 *   The file path to return the URL for.
 *
 * @return string
 *   A fully-qualified s3:// URL.
 */
function amazons3_uri_add_bucket($target) {
  $config = \Drupal\amazons3\StreamWrapperConfiguration::fromDrupalVariables();
  $url = new S3Url($config->getBucket(), $target);
  return (string) $url;
}

/**
 * Add S3 configuration to file field settings forms.
 *
 * @param array &$form
 *   The form to alter.
 * @param string $type
 *   The field type being modified.
 */
function _amazons3_field_configuration(array &$form, $type) {
  foreach (amazons3_file_like_field() as $types) {
    if ($type == $types) {
      $settings = &$form['field']['settings'];
      $bucket_setting = isset($form['#field']['settings']['amazons3_bucket']) ? $form['#field']['settings']['amazons3_bucket'] : '';

      $settings['uri_scheme']['#weight'] = 50;

      $settings['amazons3_bucket'] = array(
        '#type' => 'textfield',
        '#title' => t('Amazon S3 bucket'),
        '#description' => t(
          'Leave blank to use the site-wide default bucket <a href="@config">currently set to %bucket</a>.',
          array(
            '@config' => url('admin/config/media/amazons3'),
            '%bucket' => variable_get('amazons3_bucket', ''),
          )
        ),
        '#states' => array(
          'visible' => array(
            ':input[name="field[settings][uri_scheme]"]' => array('value' => 's3'),
          ),
        ),
        '#default_value' => $bucket_setting,
        '#element_validate' => array('amazons3_form_bucket_validate'),
        '#weight' => 51,
      );
    }
  }
}

/**
 * Element validate callback to validate a bucket name.
 *
 * @param array &$element
 *   The element to validate.
 * @param array &$form_state
 *   The current state of the form.
 * @param array $form
 *   The current form.
 */
function amazons3_form_bucket_validate(array &$element, array &$form_state, array $form) {
  $bucket = $element['#value'];
  if (empty($bucket)) {
    return;
  }

  if (!isset($form_state['values']['amazons3_hostname'])) {
    $hostname = variable_get('amazons3_hostname');
  }
  else {
    $hostname = $form_state['values']['amazons3_hostname'];
  }

  // Inject our credentials for testing.
  $config = array();
  if (isset($form_state['values']['amazons3_key']) && isset($form_state['values']['amazons3_secret'])) {
    $config['credentials'] = new Credentials($form_state['values']['amazons3_key'], $form_state['values']['amazons3_secret']);
  }

  if (!empty($hostname)) {
    $config['endpoint'] = $hostname;
  }

  try {
    $s3 = S3Client::factory($config);
    S3Client::validateBucketExists($bucket, $s3);
  }
  catch (S3ConnectValidationException $e) {
    form_error($element, t('The S3 access credentials are invalid or the bucket does not exist.'));
    watchdog_exception('amazons3', $e);
  }
  catch (Exception $e) {
    form_error($element, t('There was a problem connecting to S3. The following exception was thrown: @exception', array('@exception' => $e->getMessage())));
    watchdog_exception('amazons3', $e);
  }
}

/**
 * Implements hook_field_default_field_bases_alter().
 *
 * Allows a variable to override all exported field bases to use 'Amazon S3' as
 * the Upload destination. For example this can be added to environment-specific
 * Drupal settings files, to allow certain environments to upload to S3 while
 * other environments upload to the exported (public or private) URI scheme:
 * @code
 * $conf['amazons3_file_uri_scheme_override'] = 's3';
 * @endcode
 */
function amazons3_field_default_field_bases_alter(&$fields) {
  if ($uri_scheme = variable_get('amazons3_file_uri_scheme_override', FALSE)) {
    foreach ($fields as $key => $item) {
      if (isset($item['settings']['uri_scheme'])) {
        $fields[$key]['settings']['uri_scheme'] = $uri_scheme;
      }
    }
  }
}

function amazons3_form_shared_file_node_form_alter(&$form, &$form_state, $form_id) {
	global $user;

	$form['title'] = array(
			'#type' => 'textfield',
			'#title' => 'Title Test',
			'#element_validate' => array('amazons3_form_shared_file_node_form_title_validate')
	);
}

function amazons3_form_shared_file_node_form_title_validate($element, $form_state) {
	// If valid, share a file to a user or a role by copying the file from the sharer.
	// This way a copy of the file is given to the recipient user or role.
	// To read a URL it checks first from public then private file by user then private file by role.
	// Remember this is an additional overhead to the server.
	$err_count = 0; 
	global $user;
	
	if (isset($form_state['values']['field_file_to_share']['und']['0'])) {
		$fid = $form_state['values']['field_file_to_share']['und']['0']['fid'];
	} else {
		return;
	}

	$file_name = file_load($fid);
	
	$shared_to = $form_state['values']['field_share_to']['und'];
	$shared_to_role = $form_state['values']['field_share_to_role']['und'];

	$uri = $file_name->uri;
	$uri_exp = explode("//", $uri);
	if (isset($uri_exp[1])) {
		$f_name = $uri_exp[1];
		$source_key = $user->uid . '/' . $f_name;
		$hname = variable_get('amazons3_hostname');
		$var_bucket = variable_get("amazons3_bucket");
		// Instantiate s3 client
		$s3 = S3Client::factory([
				'region' => variable_get("amazons3_region"),
				'version' => variable_get("amazons3_version"),
				'endpoint' => variable_get("amazons3_usehttps") . $hname,
				'credentials' => array(
					'key'    => variable_get("amazons3_key"),
					'secret' => variable_get("amazons3_secret"),
				)
		]);
		
		if ($shared_to !== '_none' && $shared_to !== '') {

			$target_key = $shared_to . '/' . $f_name;
			
			try { // Catch copying
				// Check the existence of the Object in the source user folder to avoid no bucket exception later
				$bool_result = $s3->doesObjectExist($var_bucket, $source_key);
		
				if ($bool_result) { // Object exists
					$copy_result = $s3->copyObject([
						'ACL' => 'private', // Private files should be private. :)
						'Bucket' => $var_bucket, // Target bucket
						'CopySource' => "{$var_bucket}/{$source_key}", // url encoded source to copy
						'Key' => urldecode($target_key) // Target destination, should have no % # etc. 
					]);
			    } else {
			    	// The file is public no need to copy it the target folder
			    }
			
			} catch(Exception $e) {
				form_error($element, t('No file was shared. Please try again.'));
			}	
		} else {
			$err_count = $err_count + 1;
		}
		
				try { // Catch copying
					// Check the existence of the Object in the source user folder to avoid no bucket exception later
					$bool_result = $s3->doesObjectExist($var_bucket, $source_key);
				
					if ($bool_result) { // Object exists
						
						foreach ($shared_to_role as $trole) {
							if ($trole !== 0) {
								$target_key = $trole . '/' . $f_name;
						
								$copy_result = $s3->copyObject([
									'ACL' => 'private', // Private files should be private. :)
									'Bucket' => $var_bucket, // Target bucket
									'CopySource' => "{$var_bucket}/{$source_key}", // url encoded source to copy
									'Key' => urldecode($target_key) // Target destination, should have no % # etc.
								]);

							} else {
								// The file is public no need to copy it to the target folder
							}
						}
					}	
				} catch(Exception $e) {
					continue;
				}
				$err_count = 0;
	} else {
		form_error($element, t('File name is required.'));
	}
	
	if ($err_count > 0) {
		form_error($element, t('Please choose either share to a user or to a role option.'));
	}
}


/**
 * Implements hook_services_resources().
 *
 */


function amazons3_services_resources() {
	return array(
			'exoscale' => array(
					'operations' => array(
							'create' => array(
									'file' => array('type' => 'inc', 'module' => 'services', 'name' => 'resources/file_resource'),
									'help' => 'Create a file with base64 encoded data',
									'callback' => 'amazons3_file_resource_create',
									'access callback' => '_file_resource_access',
									'access arguments' => array('create'),
									'access arguments append' => TRUE,
									'args' => array(
											array(
													'name' => 'file',
													'type' => 'array',
													'description'    => t('An array representing a file.'),
													'source' => 'data',
													'optional' => FALSE
											)
									)
							),
							'retrieve' => array(
									'file' => array('type' => 'inc', 'module' => 'services', 'name' => 'resources/file_resource'),
									'help' => 'Retrieve a file',
									'callback' => 'amazons3_file_resource_retrieve',
									'access callback' => '_file_resource_access',
									'access arguments' => array('view'),
									'access arguments append' => TRUE,
									'args' => array(
											array(
													'name' => 'fid',
													'type' => 'int',
													'description' => 'The fid of the file to retrieve.',
													'source' => array('path' => '0'),
													'optional' => FALSE
											),
											array(
													'name'         => 'file_contents',
													'type'         => 'int',
													'description'  => t('To return file contents or not.'),
													'source'       => array('param' => 'file_contents'),
													'default value' => TRUE,
													'optional' => TRUE
											),
											array(
													'name'         => 'image_styles',
													'type'         => 'int',
													'description'  => t('To return image styles or not.'),
													'source'       => array('param' => 'image_styles'),
													'default value' => FALSE,
													'optional' => TRUE
											)
									)
							)
					)
			)
	);
}

/**
 * Adds a new file and returns the fid.
 *
 * @param $file
 *   An array as representing the file with a base64 encoded $file['file']
 * @return
 *   Unique identifier for the file (fid) or errors if there was a problem.
 */
function amazons3_file_resource_create($file) {
	global $user;
	
	// Adds backwards compatability with regression fixed in #1083242
	// $file['file'] can be base64 encoded file so we check whether it is
	// file array or file data.
	$file = _services_arg_value($file, 'file');

	// If the file data or filename is empty then bail.
	if (!isset($file['file']) || empty($file['filename'])) {
		return services_error(t("Missing data the file upload can not be completed"), 500);
	}
		
	try {
		$name = $file['filename'];
		
		$hname = variable_get('amazons3_hostname');
		$var_bucket = variable_get("amazons3_bucket");
		$s3 = S3Client::factory([
				'region' => variable_get("amazons3_region"),
				'version' => variable_get("amazons3_version"),
				'endpoint' => variable_get("amazons3_usehttps") . $hname,
				'credentials' => array(
					'key'    => variable_get("amazons3_key"),
					'secret' => variable_get("amazons3_secret"),
				)
		]);
		
		$f_exists_public = $s3->doesObjectExist($var_bucket, 'public/' . $name);
		$f_exists_admin  = $s3->doesObjectExist($var_bucket, 'administrator/' . $name);
		
		if ($f_exists_public || $f_exists_admin) { // If the file exists in s3
			// rename the file
			$name = "f" . date("U") . '_' . $name;
		}
				
		// Sanitize the file extension, name, path and scheme provided by the user.
		$destination = "s3://" . $name;

		if (isset($file['copy'])) { // Enable you to copy files from s3 to another folder like user folder or role folder
				
			// Source key name
			$source_key = $file['sourcekey'];
				
			$bool_result = $s3->doesObjectExist($var_bucket, $source_key);
			if ($bool_result) { // Object exists

				// Get array of roles to copy to
				$shared_to_role = explode(",", $file['role']); // Comma-separated roles
				foreach ($shared_to_role as $trole) {
					if ($trole !== 0) {
						$target_key = $trole . '/' . $name;

						$copy_result = $s3->copyObject([
							'ACL' => 'private', // Private files should be private. :)
							'Bucket' => $var_bucket, // Target bucket
							'CopySource' => "{$var_bucket}/{$source_key}", // url decoded source to copy
							'Key' => urldecode($target_key) // Target destination, should have no % # etc.
						]);
					} else {
						// The file is public no need to copy it to the target folder
					}
				}

				// Get array of uids to copy to
				$shared_to_uid = explode(",", $file['uid']); // Comma-separated uids
				foreach ($shared_to_uid as $tuid) {
					if ($tuid !== 0) {
						$target_key = $tuid . '/' . $name;

						$copy_result = $s3->copyObject([
							'ACL' => 'private', // Private files should be private. :)
							'Bucket' => $var_bucket, // Target bucket
							'CopySource' => "{$var_bucket}/{$source_key}", // url decoded source to copy
							'Key' => urldecode($target_key) // Target destination, should have no % # etc.
						]);
					} else {
						// The file is public no need to copy it to the target folder
					}
				}

				return array(
					'fid' => '',
					'uri' => '',
					'uid' => $file['uid'],
					'role' => $file['role'],
					'success' => TRUE
				);
			} else {
				return array(
					'fid' => '',
					'uri' => '',
					'uid' => '',
					'role' => '',
					'success' => FALSE,
					'message' => 'Source key does not exist'
				);
			}
		} else {
			if (isset($file['private']) && $file['private'] == "true") {
				$s3->putObject([
					'Bucket' => $var_bucket,
					'Key' => "{$user->uid}/{$name}",
					"Body" => base64_decode($file['file']),
					'ACL' => 'private'
				]);

				$s3->putObject([
					'Bucket' => $var_bucket,
					'Key' => "administrator/{$name}",
					"Body" => base64_decode($file['file']),
					'ACL' => 'private'
				]);
			} else {
				$s3->putObject([
					'Bucket' => $var_bucket,
					'Key' => "public/{$name}",
					"Body" => base64_decode($file['file']),
					'ACL' => 'public-read'
				]);
			}

			// Copy this file to a role
			if (isset($file['role'])) {
				$s3->putObject([
					'Bucket' => $var_bucket,
					'Key' => "{$file['role']}/{$name}",
					"Body" => base64_decode($file['file']),
					'ACL' => 'private'
				]);
			}
				
			// Copy this file to a user id
			if (isset($file['uid'])) {
				$s3->putObject([
					'Bucket' => $var_bucket,
					'Key' => "{$file['uid']}/{$name}",
					"Body" => base64_decode($file['file']),
					'ACL' => 'private'
				]);
			}
			
			// file save
			$file_s = new stdClass();
			$file_s->uri = $destination;
			$file_s->filename = $name;
			$file_s->filemime = file_get_mimetype($file_s->uri);
			$file_s->uid = $user->uid;
			$file_s->status = FILE_STATUS_PERMANENT;	
			
			$file_saved = file_save($file_s);
	
			if ($file_saved) {
				return array(
					'fid' => $file_saved->fid,
					'uri' => services_resource_uri(array('exoscale', $file_saved->fid))
				);
			} else {
				return services_error(t("Could not write file to destination"), 500);
			}
		}	
	} catch(S3Exception $e) {
		return services_error(t("Error uploading the file."), 500);
	}
}

/**
 * Get a given file
 *
 * @param $fid
 *   Number. File ID
 * @param $include_file_contents
 *   Bool Whether or not to include the base64_encoded version of the file.
 * @param $get_image_style
 *   Bool Whether or not to provide image style paths.
 * @return
 *   The file
 */
function amazons3_file_resource_retrieve($fid, $include_file_contents, $get_image_style) {
	if ($file = file_load($fid)) {
		$filepath = $file->uri;

		// Convert the uri to the external url path provided by the stream wrapper.
		$file->uri_full = file_create_url($file->uri);

		// Provide a path in the form sample/test.txt.
		$file->target_uri = file_uri_target($file->uri);

		if ($include_file_contents) {
			$file->file = base64_encode(file_get_contents(drupal_realpath($filepath)));
		}

		$file->image_styles = array();
		// Add image style information if available.
		if ($get_image_style && !empty($file->uri) && strpos($file->filemime, 'image') === 0) {
			foreach (image_styles() as $style) {
				$style_name = $style['name'];
				$file->image_styles[$style_name] = image_style_url($style_name, $file->uri);
			}
		}
		return $file;
	}
}
